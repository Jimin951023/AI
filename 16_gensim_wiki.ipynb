{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16.gensim_wiki.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6C46twWOIitH81+Wc+cBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jimin951023/AI/blob/main/16_gensim_wiki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec實作\n",
        "字詞所代表的意義非常多元，在不同狀況下，會代表不同意思。要把多元意思用單一向量表示，則必須要進行word embedding的動作，也就是把高維向量降為低維向量的過程\n",
        "之前介紹過，利用分散式表示法來表達字詞向量，例如PMI、SVD..統計法..等\n",
        "2013年神經網路盛行後，Tomas Mikolov利用神經網路訓練方式，來獲得字詞的表達向量，獲得很棒的成果。一般認為是利用神經網路模擬人類的理解能力，獲得不錯的分布空間所得到的成果。\n",
        "本範例以維基百科wiki部分資料作範例\n",
        "資料來源：https://dumps.wikimedia.org/zhwiki/20220401/zhwiki-20220401-pages-articles-multistream.xml.bz2\n",
        "利用結巴分詞(jieba)進行斷詞，gensim套件進行word2vec計算\n",
        "本範例約需1小時長時間執行"
      ],
      "metadata": {
        "id": "5t0eGbiI_j7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o-rn6jUV_h7E"
      },
      "outputs": [],
      "source": [
        "# ! wget https://dumps.wikimedia.org/zhwiki/20220401/zhwiki-20220401-pages-articles-multistream.xml.bz2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dumps.wikimedia.org/zhwiki/20220401/zhwiki-20220401-pages-articles-multistream1.xml-p1p187712.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ojSvaPh_vlT",
        "outputId": "b0412734-2847-48aa-82ff-636e628dbef1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-20 12:42:40--  https://dumps.wikimedia.org/zhwiki/20220401/zhwiki-20220401-pages-articles-multistream1.xml-p1p187712.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 215920539 (206M) [application/octet-stream]\n",
            "Saving to: ‘zhwiki-20220401-pages-articles-multistream1.xml-p1p187712.bz2’\n",
            "\n",
            "zhwiki-20220401-pag 100%[===================>] 205.92M  4.76MB/s    in 43s     \n",
            "\n",
            "2022-04-20 12:43:23 (4.75 MB/s) - ‘zhwiki-20220401-pages-articles-multistream1.xml-p1p187712.bz2’ saved [215920539/215920539]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencc-python-reimplemented"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7tYxDRA_xkp",
        "outputId": "ed5941ab-6a13-4ac2-e24b-e2fbbddcb3ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencc-python-reimplemented in /usr/local/lib/python3.7/dist-packages (0.1.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import WikiCorpus\n",
        "\n",
        "wiki_corpus = WikiCorpus('zhwiki-20220401-pages-articles-multistream1.xml-p1p187712.bz2', dictionary={})"
      ],
      "metadata": {
        "id": "flQLloewACMs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5onWz_QAF3W",
        "outputId": "14dc13b9-14cc-4bcb-d588-fee59d6147b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.wikicorpus.WikiCorpus at 0x7f11c5107650>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(wiki_corpus.get_texts()))[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeqUC5dmAHin",
        "outputId": "b3bcbe29-b305-446c-c26f-01a2819fdbf3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['歐幾里得',\n",
              " '西元前三世紀的古希臘數學家',\n",
              " '現在被認為是幾何之父',\n",
              " '此畫為拉斐爾的作品',\n",
              " '雅典學院',\n",
              " '数学',\n",
              " '是研究數量',\n",
              " '从某种角度看屬於形式科學的一種',\n",
              " '數學利用抽象化和邏輯推理',\n",
              " '從計數']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_num = 0\n",
        "\n",
        "with open('wiki_text.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in wiki_corpus.get_texts():\n",
        "        f.write(' '.join(text)+'\\n')\n",
        "        text_num += 1\n",
        "        if text_num % 10000 == 0:\n",
        "            print('{} articles processed.'.format(text_num))\n",
        "\n",
        "    print('{} articles processed.'.format(text_num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW-Pn_tbAeuI",
        "outputId": "464b8341-6513-455d-d0cc-1b54a2e9f775"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8948 articles processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "from opencc import OpenCC\n",
        "\n",
        "\n",
        "# Initial\n",
        "cc = OpenCC('s2t')\n",
        "train_data = open('wiki_text.txt', 'r', encoding='utf-8').read()\n",
        "train_data = cc.convert(train_data)\n",
        "train_data = jieba.lcut(train_data)\n",
        "train_data = [word for word in train_data if word != '']\n",
        "train_data = ' '.join(train_data)\n",
        "open('seg.txt', 'w', encoding='utf-8').write(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFqNgyxnAi1A",
        "outputId": "0376d0e3-fb99-42b5-e4d7-a1110a39ebf7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.002 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45133839"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "\n",
        "# Settings\n",
        "seed = 666\n",
        "sg = 0\n",
        "window_size = 10\n",
        "vector_size = 100\n",
        "min_count = 1\n",
        "workers = 8\n",
        "epochs = 5\n",
        "batch_words = 10000\n",
        "\n",
        "train_data = word2vec.LineSentence('seg.txt')\n",
        "model = word2vec.Word2Vec(\n",
        "    train_data,\n",
        "    min_count=min_count,\n",
        "    size=vector_size,\n",
        "    workers=workers,\n",
        "    iter=epochs,\n",
        "    window=window_size,\n",
        "    sg=sg,\n",
        "    seed=seed,\n",
        "    batch_words=batch_words\n",
        ")\n",
        "\n",
        "model.save('word2vec.model')"
      ],
      "metadata": {
        "id": "55jOZ6yQAzlS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "string = '電腦'\n",
        "model = word2vec.Word2Vec.load('word2vec.model')\n",
        "print(string)\n",
        "\n",
        "for item in model.wv.most_similar(string):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkUnAl6xA2Bx",
        "outputId": "b8c3cdd1-d1c3-4112-829f-d81af258d013"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "電腦\n",
            "('ibm', 0.8495076298713684)\n",
            "('手機', 0.8404494524002075)\n",
            "('廠商', 0.8402011394500732)\n",
            "('軟體', 0.8361618518829346)\n",
            "('計算機', 0.8300386071205139)\n",
            "('模擬器', 0.8217790126800537)\n",
            "('智能', 0.8212008476257324)\n",
            "('程式', 0.8131803870201111)\n",
            "('晶片', 0.8126602172851562)\n",
            "('微電腦', 0.808303952217102)\n"
          ]
        }
      ]
    }
  ]
}